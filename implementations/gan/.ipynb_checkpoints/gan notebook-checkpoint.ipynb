{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adapted from the GAN implementation in the PyTorch-GAN model zoo:\n",
    "## https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style(\"white\")\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "n_epochs = 200 #'number of epochs of training'\n",
    "batch_size = 64 #'size of the batches'\n",
    "lr = 0.0002 #'adam: learning rate'\n",
    "b1 = 0.5 #'adam: decay of first order momentum of gradient'\n",
    "b2 = 0.999 #'adam: decay of first order momentum of gradient'\n",
    "n_cpu = 4 #'number of cpu threads to use during batch generation'\n",
    "latent_dim = 100 #'dimensionality of the latent space'\n",
    "img_size = 28 #'size of each image dimension'\n",
    "channels = 1 #'number of image channels'\n",
    "sample_interval=400 #'interval betwen image samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (channels, img_size, img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs('../../data/mnist', exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data/mnist', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## useful functions for collecting triangle statistics\n",
    "\n",
    "def triplet_sample(X):\n",
    "    \"\"\"\n",
    "    given an array of images X, return a triplet\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        [i,j,k] = list(np.random.randint(0, X.shape[0], 3))\n",
    "        if len({i,j,k}) == 3:\n",
    "            return [X[i], X[j], X[k]]\n",
    "        \n",
    "        \n",
    "def distance_L2(x,y):\n",
    "    \"\"\"\n",
    "    given 2 images, x, y, return the normalized l2 distance between them,\n",
    "    normalized so that the max distance is 1\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x - y)**2))/56\n",
    "\n",
    "\n",
    "def distance_H(x,y):\n",
    "    \"\"\"\n",
    "    given 2 images, x, y, return the normalized Hamming distance between them,\n",
    "    \"\"\"\n",
    "    x_binary = np.asarray(x.reshape(784)>0)\n",
    "    y_binary = np.asarray(y.reshape(784)>0) \n",
    "    return np.count_nonzero(x_binary != y_binary)/len(x_binary)\n",
    "\n",
    "\n",
    "def triangle_distances_l2(x,y,z):\n",
    "    \"\"\"\n",
    "    return the sorted l2 distances of the triangle formed by the points (x,y,z)\n",
    "    \"\"\"\n",
    "    return sorted([distance_L2(x,y), distance_L2(x,z), distance_L2(y,z)])\n",
    "\n",
    "\n",
    "def triangle_distances_H(x,y,z):\n",
    "    \"\"\"\n",
    "    return the sorted normalized Hamming distances of the triangle formed by the points (x,y,z)\n",
    "    \"\"\"\n",
    "    return sorted([distance_H(x,y), distance_H(x,z), distance_H(y,z)])\n",
    "\n",
    "\n",
    "def angles(dxy, dxz, dyz):\n",
    "    \"\"\"\n",
    "    Given the 3 distances of a triangle, return the sorted angles\n",
    "    \"\"\"\n",
    "    theta_xy = np.arccos((-dxy**2 + dxz**2 + dyz**2)/(2*dxz*dyz))\n",
    "    theta_xz = np.arccos((dxy**2 - dxz**2 + dyz**2)/(2*dxy*dyz))\n",
    "    theta_yz = np.arccos((dxy**2 + dxz**2 - dyz**2)/(2*dxy*dxz))\n",
    "    return sorted([theta_xy, theta_xz, theta_yz])\n",
    "\n",
    "\n",
    "def triangle_distributions(X, Num):\n",
    "    \"\"\"\n",
    "    Given an array of samples 4, generate two arrays of shape (Num, 2).\n",
    "    \n",
    "    Array 1: the 2 dimensions are [dmid-dmin, dmax-dmid] (l2 distance)\n",
    "    Array 2: the 2 dimensions are [theta_min/theta_max, theta_min/theta_mid] (l2 distance)\n",
    "    Array 3: the 2 dimensions are [dmid-dmin, dmax-dmid] (Hamming distance)\n",
    "    Array 4: the 2 dimensions are [theta_min/theta_max, theta_min/theta_mid] (Hamming distance)\n",
    "    \"\"\"\n",
    "\n",
    "    K_distances_l2 = np.zeros((Num,2))\n",
    "    K_angles_l2 = np.zeros((Num,2))\n",
    "    K_distances_H = np.zeros((Num,2))\n",
    "    K_angles_H = np.zeros((Num,2))\n",
    "    \n",
    "    for i in range(Num):\n",
    "        [x, y, z] = triplet_sample(X)\n",
    "        \n",
    "        ## l2 distances\n",
    "        [d_min, d_mid, d_max] = triangle_distances_l2(x,y,z)\n",
    "        [theta_min, theta_mid, theta_max] = angles(d_min, d_mid, d_max)        \n",
    "\n",
    "        K_distances_l2[i,0] = d_mid - d_min\n",
    "        K_distances_l2[i,1] = d_max - d_mid        \n",
    "        K_angles_l2[i,0] = theta_min/theta_mid\n",
    "        K_angles_l2[i,1] = theta_min/theta_max\n",
    "\n",
    "        ## Hamming distances\n",
    "        [d_min, d_mid, d_max] = triangle_distances_l2(x,y,z)\n",
    "        [theta_min, theta_mid, theta_max] = angles(d_min, d_mid, d_max)        \n",
    "\n",
    "        K_distances_H[i,0] = d_mid - d_min\n",
    "        K_distances_H[i,1] = d_max - d_mid        \n",
    "        K_angles_H[i,0] = theta_min/theta_mid\n",
    "        K_angles_H[i,1] = theta_min/theta_max\n",
    "\n",
    "        \n",
    "    return [K_distances_l2, K_angles_l2, K_distances_H, K_angles_H]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/938] [D loss: 0.688701] [G loss: 0.677683]\n",
      "g_overlap: 0.216, d_overlap: 0.773\n",
      "[Epoch 0/200] [Batch 400/938] [D loss: 0.258009] [G loss: 1.609930]\n",
      "g_overlap: 0.951, d_overlap: 0.990\n",
      "[Epoch 0/200] [Batch 800/938] [D loss: 0.203303] [G loss: 1.816874]\n",
      "g_overlap: 0.942, d_overlap: 0.996\n",
      "[Epoch 1/200] [Batch 262/938] [D loss: 0.390825] [G loss: 3.704893]\n",
      "g_overlap: 0.931, d_overlap: 0.991\n",
      "[Epoch 1/200] [Batch 662/938] [D loss: 0.320707] [G loss: 1.870255]\n",
      "g_overlap: 0.913, d_overlap: 0.997\n",
      "[Epoch 2/200] [Batch 124/938] [D loss: 0.577738] [G loss: 3.304211]\n",
      "g_overlap: 0.970, d_overlap: 0.999\n",
      "[Epoch 2/200] [Batch 524/938] [D loss: 1.039650] [G loss: 5.272514]\n",
      "g_overlap: 0.974, d_overlap: 1.000\n",
      "[Epoch 2/200] [Batch 924/938] [D loss: 0.186921] [G loss: 1.705590]\n",
      "g_overlap: 0.767, d_overlap: 0.987\n",
      "[Epoch 3/200] [Batch 386/938] [D loss: 0.192280] [G loss: 1.663037]\n",
      "g_overlap: 0.706, d_overlap: 0.987\n",
      "[Epoch 3/200] [Batch 786/938] [D loss: 0.140529] [G loss: 2.960330]\n",
      "g_overlap: 0.489, d_overlap: 0.946\n",
      "[Epoch 4/200] [Batch 248/938] [D loss: 0.319479] [G loss: 1.817683]\n",
      "g_overlap: 0.940, d_overlap: 0.999\n",
      "[Epoch 4/200] [Batch 648/938] [D loss: 0.260818] [G loss: 2.621036]\n",
      "g_overlap: 0.930, d_overlap: 0.995\n",
      "[Epoch 5/200] [Batch 110/938] [D loss: 0.148784] [G loss: 2.245836]\n",
      "g_overlap: 0.640, d_overlap: 0.991\n",
      "[Epoch 5/200] [Batch 510/938] [D loss: 0.253233] [G loss: 1.708292]\n",
      "g_overlap: 0.752, d_overlap: 0.991\n",
      "[Epoch 5/200] [Batch 910/938] [D loss: 0.181364] [G loss: 2.130634]\n",
      "g_overlap: 0.645, d_overlap: 0.994\n",
      "[Epoch 6/200] [Batch 372/938] [D loss: 0.338120] [G loss: 1.049885]\n",
      "g_overlap: 0.574, d_overlap: 0.982\n",
      "[Epoch 6/200] [Batch 772/938] [D loss: 0.238866] [G loss: 1.867664]\n",
      "g_overlap: 0.899, d_overlap: 0.998\n",
      "[Epoch 7/200] [Batch 234/938] [D loss: 0.284812] [G loss: 2.166430]\n",
      "g_overlap: 0.902, d_overlap: 0.994\n",
      "[Epoch 7/200] [Batch 634/938] [D loss: 0.451514] [G loss: 0.772684]\n",
      "g_overlap: -0.209, d_overlap: 0.462\n",
      "[Epoch 8/200] [Batch 96/938] [D loss: 0.449420] [G loss: 3.196947]\n",
      "g_overlap: 0.884, d_overlap: 0.996\n",
      "[Epoch 8/200] [Batch 496/938] [D loss: 0.355538] [G loss: 1.057008]\n",
      "g_overlap: 0.406, d_overlap: 0.944\n",
      "[Epoch 8/200] [Batch 896/938] [D loss: 0.223430] [G loss: 1.768732]\n",
      "g_overlap: 0.751, d_overlap: 0.992\n",
      "[Epoch 9/200] [Batch 358/938] [D loss: 0.313687] [G loss: 1.500239]\n",
      "g_overlap: 0.795, d_overlap: 0.996\n",
      "[Epoch 9/200] [Batch 758/938] [D loss: 0.285126] [G loss: 1.544798]\n",
      "g_overlap: 0.831, d_overlap: 0.994\n",
      "[Epoch 10/200] [Batch 220/938] [D loss: 0.230540] [G loss: 1.629992]\n",
      "g_overlap: 0.554, d_overlap: 0.991\n",
      "[Epoch 10/200] [Batch 620/938] [D loss: 0.236576] [G loss: 1.960762]\n",
      "g_overlap: 0.628, d_overlap: 0.994\n",
      "[Epoch 11/200] [Batch 82/938] [D loss: 0.219351] [G loss: 2.377234]\n",
      "g_overlap: 0.777, d_overlap: 0.995\n",
      "[Epoch 11/200] [Batch 482/938] [D loss: 0.141264] [G loss: 2.549349]\n",
      "g_overlap: 0.690, d_overlap: 0.993\n",
      "[Epoch 11/200] [Batch 882/938] [D loss: 0.341794] [G loss: 2.205098]\n",
      "g_overlap: 0.639, d_overlap: 0.985\n",
      "[Epoch 12/200] [Batch 344/938] [D loss: 0.156524] [G loss: 1.888038]\n",
      "g_overlap: 0.500, d_overlap: 0.986\n",
      "[Epoch 12/200] [Batch 744/938] [D loss: 0.370067] [G loss: 0.982285]\n",
      "g_overlap: -0.015, d_overlap: 0.891\n",
      "[Epoch 13/200] [Batch 206/938] [D loss: 0.484504] [G loss: 3.729189]\n",
      "g_overlap: 0.810, d_overlap: 0.995\n",
      "[Epoch 13/200] [Batch 606/938] [D loss: 1.326078] [G loss: 6.451417]\n",
      "g_overlap: 0.687, d_overlap: 0.975\n",
      "[Epoch 14/200] [Batch 68/938] [D loss: 0.201787] [G loss: 2.688857]\n",
      "g_overlap: 0.559, d_overlap: 0.991\n",
      "[Epoch 14/200] [Batch 468/938] [D loss: 0.290784] [G loss: 1.693169]\n",
      "g_overlap: 0.571, d_overlap: 0.987\n",
      "[Epoch 14/200] [Batch 868/938] [D loss: 0.199889] [G loss: 2.456849]\n",
      "g_overlap: 0.581, d_overlap: 0.993\n",
      "[Epoch 15/200] [Batch 330/938] [D loss: 0.263079] [G loss: 3.039637]\n",
      "g_overlap: 0.667, d_overlap: 0.992\n",
      "[Epoch 15/200] [Batch 730/938] [D loss: 0.460239] [G loss: 3.832358]\n",
      "g_overlap: 0.630, d_overlap: 0.992\n",
      "[Epoch 16/200] [Batch 192/938] [D loss: 0.414867] [G loss: 0.784575]\n",
      "g_overlap: 0.307, d_overlap: 0.753\n",
      "[Epoch 16/200] [Batch 592/938] [D loss: 0.326421] [G loss: 2.117198]\n",
      "g_overlap: 0.688, d_overlap: 0.995\n",
      "[Epoch 17/200] [Batch 54/938] [D loss: 0.304970] [G loss: 3.624465]\n",
      "g_overlap: 0.724, d_overlap: 0.991\n",
      "[Epoch 17/200] [Batch 454/938] [D loss: 0.298557] [G loss: 1.144282]\n",
      "g_overlap: 0.348, d_overlap: 0.903\n",
      "[Epoch 17/200] [Batch 854/938] [D loss: 0.216695] [G loss: 1.772588]\n",
      "g_overlap: 0.440, d_overlap: 0.986\n",
      "[Epoch 18/200] [Batch 316/938] [D loss: 0.357436] [G loss: 1.094657]\n",
      "g_overlap: 0.424, d_overlap: 0.966\n",
      "[Epoch 18/200] [Batch 716/938] [D loss: 0.407611] [G loss: 0.912340]\n",
      "g_overlap: 0.211, d_overlap: 0.858\n",
      "[Epoch 19/200] [Batch 178/938] [D loss: 0.219979] [G loss: 2.465415]\n",
      "g_overlap: 0.678, d_overlap: 0.995\n",
      "[Epoch 19/200] [Batch 578/938] [D loss: 0.225853] [G loss: 1.699417]\n",
      "g_overlap: 0.418, d_overlap: 0.969\n",
      "[Epoch 20/200] [Batch 40/938] [D loss: 0.369272] [G loss: 3.264655]\n",
      "g_overlap: 0.686, d_overlap: 0.987\n",
      "[Epoch 20/200] [Batch 440/938] [D loss: 0.370670] [G loss: 1.089603]\n",
      "g_overlap: 0.377, d_overlap: 0.933\n",
      "[Epoch 20/200] [Batch 840/938] [D loss: 0.303383] [G loss: 2.348223]\n",
      "g_overlap: 0.663, d_overlap: 0.988\n",
      "[Epoch 21/200] [Batch 302/938] [D loss: 0.288744] [G loss: 2.980943]\n",
      "g_overlap: 0.575, d_overlap: 0.986\n",
      "[Epoch 21/200] [Batch 702/938] [D loss: 0.259634] [G loss: 2.587278]\n",
      "g_overlap: 0.624, d_overlap: 0.984\n",
      "[Epoch 22/200] [Batch 164/938] [D loss: 0.389563] [G loss: 0.929879]\n",
      "g_overlap: 0.273, d_overlap: 0.954\n",
      "[Epoch 22/200] [Batch 564/938] [D loss: 0.305777] [G loss: 1.363055]\n",
      "g_overlap: 0.478, d_overlap: 0.984\n",
      "[Epoch 23/200] [Batch 26/938] [D loss: 0.290710] [G loss: 2.614829]\n",
      "g_overlap: 0.677, d_overlap: 0.995\n",
      "[Epoch 23/200] [Batch 426/938] [D loss: 0.326986] [G loss: 1.790445]\n",
      "g_overlap: 0.602, d_overlap: 0.990\n",
      "[Epoch 23/200] [Batch 826/938] [D loss: 0.262199] [G loss: 1.757841]\n",
      "g_overlap: 0.433, d_overlap: 0.991\n",
      "[Epoch 24/200] [Batch 288/938] [D loss: 0.403178] [G loss: 1.343022]\n",
      "g_overlap: 0.595, d_overlap: 0.994\n",
      "[Epoch 24/200] [Batch 688/938] [D loss: 0.231006] [G loss: 1.722765]\n",
      "g_overlap: 0.478, d_overlap: 0.978\n",
      "[Epoch 25/200] [Batch 150/938] [D loss: 0.327172] [G loss: 1.242932]\n",
      "g_overlap: 0.486, d_overlap: 0.978\n",
      "[Epoch 25/200] [Batch 550/938] [D loss: 0.391954] [G loss: 1.167895]\n",
      "g_overlap: 0.599, d_overlap: 0.993\n",
      "[Epoch 26/200] [Batch 12/938] [D loss: 0.381911] [G loss: 1.652011]\n",
      "g_overlap: 0.665, d_overlap: 0.991\n",
      "[Epoch 26/200] [Batch 412/938] [D loss: 0.328915] [G loss: 1.521439]\n",
      "g_overlap: 0.583, d_overlap: 0.993\n",
      "[Epoch 26/200] [Batch 812/938] [D loss: 0.308905] [G loss: 1.695230]\n",
      "g_overlap: 0.554, d_overlap: 0.993\n",
      "[Epoch 27/200] [Batch 274/938] [D loss: 0.403455] [G loss: 1.144019]\n",
      "g_overlap: 0.505, d_overlap: 0.986\n",
      "[Epoch 27/200] [Batch 674/938] [D loss: 0.333631] [G loss: 2.231875]\n",
      "g_overlap: 0.667, d_overlap: 0.995\n",
      "[Epoch 28/200] [Batch 136/938] [D loss: 0.361245] [G loss: 2.180555]\n",
      "g_overlap: 0.684, d_overlap: 0.992\n",
      "[Epoch 28/200] [Batch 536/938] [D loss: 0.717667] [G loss: 0.483281]\n",
      "g_overlap: 0.180, d_overlap: 0.885\n",
      "[Epoch 28/200] [Batch 936/938] [D loss: 0.388020] [G loss: 2.046248]\n",
      "g_overlap: 0.682, d_overlap: 0.985\n",
      "[Epoch 29/200] [Batch 398/938] [D loss: 0.445096] [G loss: 2.544364]\n",
      "g_overlap: 0.690, d_overlap: 0.996\n",
      "[Epoch 29/200] [Batch 798/938] [D loss: 0.337539] [G loss: 1.792029]\n",
      "g_overlap: 0.613, d_overlap: 0.995\n",
      "[Epoch 30/200] [Batch 260/938] [D loss: 0.355121] [G loss: 1.958168]\n",
      "g_overlap: 0.560, d_overlap: 0.996\n",
      "[Epoch 30/200] [Batch 660/938] [D loss: 0.492873] [G loss: 0.982035]\n",
      "g_overlap: 0.494, d_overlap: 0.986\n",
      "[Epoch 31/200] [Batch 122/938] [D loss: 0.388320] [G loss: 1.361887]\n",
      "g_overlap: 0.559, d_overlap: 0.990\n",
      "[Epoch 31/200] [Batch 522/938] [D loss: 0.423695] [G loss: 2.226165]\n",
      "g_overlap: 0.608, d_overlap: 0.994\n",
      "[Epoch 31/200] [Batch 922/938] [D loss: 0.379712] [G loss: 1.310674]\n",
      "g_overlap: 0.355, d_overlap: 0.985\n",
      "[Epoch 32/200] [Batch 384/938] [D loss: 0.457393] [G loss: 1.929238]\n",
      "g_overlap: 0.720, d_overlap: 0.993\n",
      "[Epoch 32/200] [Batch 784/938] [D loss: 0.403570] [G loss: 1.042742]\n",
      "g_overlap: 0.329, d_overlap: 0.974\n",
      "[Epoch 33/200] [Batch 246/938] [D loss: 0.317926] [G loss: 1.857015]\n",
      "g_overlap: 0.590, d_overlap: 0.987\n",
      "[Epoch 33/200] [Batch 646/938] [D loss: 0.369818] [G loss: 1.470646]\n",
      "g_overlap: 0.532, d_overlap: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/200] [Batch 108/938] [D loss: 0.301051] [G loss: 2.165290]\n",
      "g_overlap: 0.569, d_overlap: 0.991\n",
      "[Epoch 34/200] [Batch 508/938] [D loss: 0.407986] [G loss: 1.028710]\n",
      "g_overlap: 0.404, d_overlap: 0.985\n",
      "[Epoch 34/200] [Batch 908/938] [D loss: 0.276858] [G loss: 2.465076]\n",
      "g_overlap: 0.503, d_overlap: 0.987\n",
      "[Epoch 35/200] [Batch 370/938] [D loss: 0.396842] [G loss: 2.000546]\n",
      "g_overlap: 0.464, d_overlap: 0.989\n",
      "[Epoch 35/200] [Batch 770/938] [D loss: 0.503860] [G loss: 2.785042]\n",
      "g_overlap: 0.786, d_overlap: 0.995\n",
      "[Epoch 36/200] [Batch 232/938] [D loss: 0.349920] [G loss: 2.388284]\n",
      "g_overlap: 0.642, d_overlap: 0.991\n",
      "[Epoch 36/200] [Batch 632/938] [D loss: 0.338377] [G loss: 2.045944]\n",
      "g_overlap: 0.666, d_overlap: 0.989\n",
      "[Epoch 37/200] [Batch 94/938] [D loss: 0.445700] [G loss: 1.020635]\n",
      "g_overlap: 0.518, d_overlap: 0.987\n",
      "[Epoch 37/200] [Batch 494/938] [D loss: 0.420948] [G loss: 1.284298]\n",
      "g_overlap: 0.653, d_overlap: 0.991\n",
      "[Epoch 37/200] [Batch 894/938] [D loss: 0.384187] [G loss: 1.550710]\n",
      "g_overlap: 0.426, d_overlap: 0.984\n",
      "[Epoch 38/200] [Batch 356/938] [D loss: 0.285130] [G loss: 1.330211]\n",
      "g_overlap: 0.438, d_overlap: 0.984\n",
      "[Epoch 38/200] [Batch 756/938] [D loss: 0.323448] [G loss: 1.731952]\n",
      "g_overlap: 0.521, d_overlap: 0.993\n",
      "[Epoch 39/200] [Batch 218/938] [D loss: 0.263852] [G loss: 1.876454]\n",
      "g_overlap: 0.634, d_overlap: 0.990\n",
      "[Epoch 39/200] [Batch 618/938] [D loss: 0.401595] [G loss: 1.866828]\n",
      "g_overlap: 0.681, d_overlap: 0.994\n",
      "[Epoch 40/200] [Batch 80/938] [D loss: 0.300893] [G loss: 1.513760]\n",
      "g_overlap: 0.583, d_overlap: 0.981\n",
      "[Epoch 40/200] [Batch 480/938] [D loss: 0.557009] [G loss: 2.937592]\n",
      "g_overlap: 0.558, d_overlap: 0.992\n",
      "[Epoch 40/200] [Batch 880/938] [D loss: 0.379687] [G loss: 2.436024]\n",
      "g_overlap: 0.324, d_overlap: 0.986\n",
      "[Epoch 41/200] [Batch 342/938] [D loss: 0.332165] [G loss: 2.340985]\n",
      "g_overlap: 0.701, d_overlap: 0.993\n",
      "[Epoch 41/200] [Batch 742/938] [D loss: 0.421624] [G loss: 2.219007]\n",
      "g_overlap: 0.764, d_overlap: 0.995\n",
      "[Epoch 42/200] [Batch 204/938] [D loss: 0.391713] [G loss: 1.394012]\n",
      "g_overlap: 0.579, d_overlap: 0.990\n",
      "[Epoch 42/200] [Batch 604/938] [D loss: 0.355023] [G loss: 1.683259]\n",
      "g_overlap: 0.640, d_overlap: 0.988\n",
      "[Epoch 43/200] [Batch 66/938] [D loss: 0.601354] [G loss: 3.358223]\n",
      "g_overlap: 0.601, d_overlap: 0.988\n",
      "[Epoch 43/200] [Batch 466/938] [D loss: 0.323484] [G loss: 1.429682]\n",
      "g_overlap: 0.576, d_overlap: 0.987\n",
      "[Epoch 43/200] [Batch 866/938] [D loss: 0.351267] [G loss: 1.470016]\n",
      "g_overlap: 0.398, d_overlap: 0.989\n",
      "[Epoch 44/200] [Batch 328/938] [D loss: 0.498672] [G loss: 3.104138]\n",
      "g_overlap: 0.590, d_overlap: 0.987\n",
      "[Epoch 44/200] [Batch 728/938] [D loss: 0.354546] [G loss: 1.786018]\n",
      "g_overlap: 0.615, d_overlap: 0.988\n",
      "[Epoch 45/200] [Batch 190/938] [D loss: 0.370423] [G loss: 1.705572]\n",
      "g_overlap: 0.576, d_overlap: 0.987\n",
      "[Epoch 45/200] [Batch 590/938] [D loss: 0.359353] [G loss: 1.609206]\n",
      "g_overlap: 0.564, d_overlap: 0.988\n",
      "[Epoch 46/200] [Batch 52/938] [D loss: 0.360297] [G loss: 2.232990]\n",
      "g_overlap: 0.652, d_overlap: 0.994\n",
      "[Epoch 46/200] [Batch 452/938] [D loss: 0.394604] [G loss: 1.866621]\n",
      "g_overlap: 0.518, d_overlap: 0.991\n",
      "[Epoch 46/200] [Batch 852/938] [D loss: 0.427697] [G loss: 1.634607]\n",
      "g_overlap: 0.525, d_overlap: 0.994\n",
      "[Epoch 47/200] [Batch 314/938] [D loss: 0.354800] [G loss: 1.245188]\n",
      "g_overlap: 0.465, d_overlap: 0.977\n",
      "[Epoch 47/200] [Batch 714/938] [D loss: 0.338180] [G loss: 1.217739]\n",
      "g_overlap: 0.457, d_overlap: 0.971\n",
      "[Epoch 48/200] [Batch 176/938] [D loss: 0.387241] [G loss: 1.746523]\n",
      "g_overlap: 0.583, d_overlap: 0.992\n",
      "[Epoch 48/200] [Batch 576/938] [D loss: 0.322105] [G loss: 2.119416]\n",
      "g_overlap: 0.669, d_overlap: 0.991\n",
      "[Epoch 49/200] [Batch 38/938] [D loss: 0.456726] [G loss: 1.916749]\n",
      "g_overlap: 0.640, d_overlap: 0.994\n",
      "[Epoch 49/200] [Batch 438/938] [D loss: 0.350641] [G loss: 2.103740]\n",
      "g_overlap: 0.500, d_overlap: 0.990\n",
      "[Epoch 49/200] [Batch 838/938] [D loss: 0.281226] [G loss: 1.652912]\n",
      "g_overlap: 0.555, d_overlap: 0.981\n",
      "[Epoch 50/200] [Batch 300/938] [D loss: 0.368099] [G loss: 1.913333]\n",
      "g_overlap: 0.542, d_overlap: 0.986\n",
      "[Epoch 50/200] [Batch 700/938] [D loss: 0.355557] [G loss: 1.747194]\n",
      "g_overlap: 0.525, d_overlap: 0.987\n",
      "[Epoch 51/200] [Batch 162/938] [D loss: 0.448303] [G loss: 1.888826]\n",
      "g_overlap: 0.632, d_overlap: 0.988\n",
      "[Epoch 51/200] [Batch 562/938] [D loss: 0.395955] [G loss: 1.530019]\n",
      "g_overlap: 0.581, d_overlap: 0.992\n",
      "[Epoch 52/200] [Batch 24/938] [D loss: 0.386304] [G loss: 2.165481]\n",
      "g_overlap: 0.759, d_overlap: 0.990\n",
      "[Epoch 52/200] [Batch 424/938] [D loss: 0.349704] [G loss: 1.674353]\n",
      "g_overlap: 0.567, d_overlap: 0.984\n",
      "[Epoch 52/200] [Batch 824/938] [D loss: 0.408207] [G loss: 1.266596]\n",
      "g_overlap: 0.672, d_overlap: 0.990\n",
      "[Epoch 53/200] [Batch 286/938] [D loss: 0.406748] [G loss: 1.495113]\n",
      "g_overlap: 0.520, d_overlap: 0.984\n",
      "[Epoch 53/200] [Batch 686/938] [D loss: 0.429130] [G loss: 1.088785]\n",
      "g_overlap: 0.479, d_overlap: 0.971\n",
      "[Epoch 54/200] [Batch 148/938] [D loss: 0.351906] [G loss: 1.704890]\n",
      "g_overlap: 0.330, d_overlap: 0.980\n",
      "[Epoch 54/200] [Batch 548/938] [D loss: 0.359968] [G loss: 2.204399]\n",
      "g_overlap: 0.593, d_overlap: 0.987\n",
      "[Epoch 55/200] [Batch 10/938] [D loss: 0.429035] [G loss: 1.548660]\n",
      "g_overlap: 0.578, d_overlap: 0.991\n",
      "[Epoch 55/200] [Batch 410/938] [D loss: 0.334234] [G loss: 1.995381]\n",
      "g_overlap: 0.664, d_overlap: 0.988\n",
      "[Epoch 55/200] [Batch 810/938] [D loss: 0.384596] [G loss: 1.735568]\n",
      "g_overlap: 0.578, d_overlap: 0.990\n",
      "[Epoch 56/200] [Batch 272/938] [D loss: 0.339213] [G loss: 1.442287]\n",
      "g_overlap: 0.493, d_overlap: 0.978\n",
      "[Epoch 56/200] [Batch 672/938] [D loss: 0.334455] [G loss: 2.276351]\n",
      "g_overlap: 0.694, d_overlap: 0.989\n",
      "[Epoch 57/200] [Batch 134/938] [D loss: 0.342754] [G loss: 1.388427]\n",
      "g_overlap: 0.532, d_overlap: 0.975\n",
      "[Epoch 57/200] [Batch 534/938] [D loss: 0.294351] [G loss: 2.199907]\n",
      "g_overlap: 0.382, d_overlap: 0.981\n",
      "[Epoch 57/200] [Batch 934/938] [D loss: 0.312749] [G loss: 1.844600]\n",
      "g_overlap: 0.525, d_overlap: 0.987\n",
      "[Epoch 58/200] [Batch 396/938] [D loss: 0.426278] [G loss: 1.458830]\n",
      "g_overlap: 0.687, d_overlap: 0.987\n",
      "[Epoch 58/200] [Batch 796/938] [D loss: 0.400680] [G loss: 1.461872]\n",
      "g_overlap: 0.564, d_overlap: 0.987\n",
      "[Epoch 59/200] [Batch 258/938] [D loss: 0.378405] [G loss: 1.641876]\n",
      "g_overlap: 0.493, d_overlap: 0.985\n",
      "[Epoch 59/200] [Batch 658/938] [D loss: 0.474275] [G loss: 1.033620]\n",
      "g_overlap: 0.470, d_overlap: 0.970\n",
      "[Epoch 60/200] [Batch 120/938] [D loss: 0.377510] [G loss: 1.181120]\n",
      "g_overlap: 0.490, d_overlap: 0.980\n",
      "[Epoch 60/200] [Batch 520/938] [D loss: 0.297102] [G loss: 1.850209]\n",
      "g_overlap: 0.681, d_overlap: 0.985\n",
      "[Epoch 60/200] [Batch 920/938] [D loss: 0.447488] [G loss: 2.333731]\n",
      "g_overlap: 0.380, d_overlap: 0.977\n",
      "[Epoch 61/200] [Batch 382/938] [D loss: 0.435716] [G loss: 2.068811]\n",
      "g_overlap: 0.367, d_overlap: 0.990\n",
      "[Epoch 61/200] [Batch 782/938] [D loss: 0.358330] [G loss: 1.568872]\n",
      "g_overlap: 0.620, d_overlap: 0.988\n",
      "[Epoch 62/200] [Batch 244/938] [D loss: 0.318289] [G loss: 2.116135]\n",
      "g_overlap: -0.220, d_overlap: 0.981\n",
      "[Epoch 62/200] [Batch 644/938] [D loss: 0.338549] [G loss: 1.602822]\n",
      "g_overlap: 0.488, d_overlap: 0.985\n",
      "[Epoch 63/200] [Batch 106/938] [D loss: 0.400892] [G loss: 1.123347]\n",
      "g_overlap: 0.296, d_overlap: 0.987\n",
      "[Epoch 63/200] [Batch 506/938] [D loss: 0.474017] [G loss: 1.876895]\n",
      "g_overlap: 0.693, d_overlap: 0.979\n",
      "[Epoch 63/200] [Batch 906/938] [D loss: 0.415472] [G loss: 1.830785]\n",
      "g_overlap: 0.548, d_overlap: 0.980\n",
      "[Epoch 64/200] [Batch 368/938] [D loss: 0.398178] [G loss: 1.582740]\n",
      "g_overlap: 0.570, d_overlap: 0.982\n",
      "[Epoch 64/200] [Batch 768/938] [D loss: 0.463199] [G loss: 1.204025]\n",
      "g_overlap: 0.377, d_overlap: 0.983\n",
      "[Epoch 65/200] [Batch 230/938] [D loss: 0.368665] [G loss: 1.838990]\n",
      "g_overlap: 0.568, d_overlap: 0.985\n",
      "[Epoch 65/200] [Batch 630/938] [D loss: 0.398162] [G loss: 1.598266]\n",
      "g_overlap: 0.269, d_overlap: 0.983\n",
      "[Epoch 66/200] [Batch 92/938] [D loss: 0.469586] [G loss: 2.195148]\n",
      "g_overlap: 0.701, d_overlap: 0.983\n",
      "[Epoch 66/200] [Batch 492/938] [D loss: 0.368962] [G loss: 1.557913]\n",
      "g_overlap: 0.440, d_overlap: 0.984\n",
      "[Epoch 66/200] [Batch 892/938] [D loss: 0.345163] [G loss: 1.758039]\n",
      "g_overlap: 0.588, d_overlap: 0.981\n",
      "[Epoch 67/200] [Batch 354/938] [D loss: 0.327938] [G loss: 1.698459]\n",
      "g_overlap: 0.506, d_overlap: 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 67/200] [Batch 754/938] [D loss: 0.391158] [G loss: 1.199843]\n",
      "g_overlap: 0.534, d_overlap: 0.981\n",
      "[Epoch 68/200] [Batch 216/938] [D loss: 0.387396] [G loss: 1.795780]\n",
      "g_overlap: 0.483, d_overlap: 0.983\n",
      "[Epoch 68/200] [Batch 616/938] [D loss: 0.412170] [G loss: 1.638805]\n",
      "g_overlap: 0.495, d_overlap: 0.980\n",
      "[Epoch 69/200] [Batch 78/938] [D loss: 0.385454] [G loss: 1.668793]\n",
      "g_overlap: 0.568, d_overlap: 0.978\n",
      "[Epoch 69/200] [Batch 478/938] [D loss: 0.460256] [G loss: 1.951645]\n",
      "g_overlap: 0.658, d_overlap: 0.990\n",
      "[Epoch 69/200] [Batch 878/938] [D loss: 0.372828] [G loss: 1.350397]\n",
      "g_overlap: 0.501, d_overlap: 0.977\n",
      "[Epoch 70/200] [Batch 340/938] [D loss: 0.427908] [G loss: 1.095496]\n",
      "g_overlap: 0.590, d_overlap: 0.982\n",
      "[Epoch 70/200] [Batch 740/938] [D loss: 0.318863] [G loss: 1.892309]\n",
      "g_overlap: 0.547, d_overlap: 0.980\n",
      "[Epoch 71/200] [Batch 202/938] [D loss: 0.377150] [G loss: 1.300328]\n",
      "g_overlap: 0.620, d_overlap: 0.983\n",
      "[Epoch 71/200] [Batch 602/938] [D loss: 0.335961] [G loss: 1.392555]\n",
      "g_overlap: 0.300, d_overlap: 0.978\n",
      "[Epoch 72/200] [Batch 64/938] [D loss: 0.261416] [G loss: 2.147432]\n",
      "g_overlap: 0.697, d_overlap: 0.979\n",
      "[Epoch 72/200] [Batch 464/938] [D loss: 0.475947] [G loss: 1.352993]\n",
      "g_overlap: 0.603, d_overlap: 0.990\n",
      "[Epoch 72/200] [Batch 864/938] [D loss: 0.346869] [G loss: 1.785374]\n",
      "g_overlap: 0.663, d_overlap: 0.974\n",
      "[Epoch 73/200] [Batch 326/938] [D loss: 0.311735] [G loss: 1.928442]\n",
      "g_overlap: 0.556, d_overlap: 0.974\n",
      "[Epoch 73/200] [Batch 726/938] [D loss: 0.348330] [G loss: 1.328191]\n",
      "g_overlap: 0.542, d_overlap: 0.987\n",
      "[Epoch 74/200] [Batch 188/938] [D loss: 0.324520] [G loss: 1.574493]\n",
      "g_overlap: 0.631, d_overlap: 0.985\n",
      "[Epoch 74/200] [Batch 588/938] [D loss: 0.317050] [G loss: 1.806427]\n",
      "g_overlap: 0.549, d_overlap: 0.985\n",
      "[Epoch 75/200] [Batch 50/938] [D loss: 0.283175] [G loss: 1.557276]\n",
      "g_overlap: 0.397, d_overlap: 0.985\n",
      "[Epoch 75/200] [Batch 450/938] [D loss: 0.350587] [G loss: 1.787213]\n",
      "g_overlap: 0.617, d_overlap: 0.980\n",
      "[Epoch 75/200] [Batch 850/938] [D loss: 0.305065] [G loss: 1.904768]\n",
      "g_overlap: 0.354, d_overlap: 0.971\n",
      "[Epoch 76/200] [Batch 312/938] [D loss: 0.317300] [G loss: 1.556311]\n",
      "g_overlap: 0.624, d_overlap: 0.971\n",
      "[Epoch 76/200] [Batch 712/938] [D loss: 0.424059] [G loss: 1.737072]\n",
      "g_overlap: 0.556, d_overlap: 0.972\n",
      "[Epoch 77/200] [Batch 174/938] [D loss: 0.425299] [G loss: 2.451761]\n",
      "g_overlap: 0.555, d_overlap: 0.974\n",
      "[Epoch 77/200] [Batch 574/938] [D loss: 0.343175] [G loss: 2.311091]\n",
      "g_overlap: 0.546, d_overlap: 0.975\n",
      "[Epoch 78/200] [Batch 36/938] [D loss: 0.299268] [G loss: 1.525131]\n",
      "g_overlap: 0.580, d_overlap: 0.981\n",
      "[Epoch 78/200] [Batch 436/938] [D loss: 0.392079] [G loss: 1.911804]\n",
      "g_overlap: 0.567, d_overlap: 0.978\n",
      "[Epoch 78/200] [Batch 836/938] [D loss: 0.341375] [G loss: 2.325117]\n",
      "g_overlap: 0.490, d_overlap: 0.978\n",
      "[Epoch 79/200] [Batch 298/938] [D loss: 0.446354] [G loss: 1.578373]\n",
      "g_overlap: 0.601, d_overlap: 0.972\n",
      "[Epoch 79/200] [Batch 698/938] [D loss: 0.408877] [G loss: 1.808615]\n",
      "g_overlap: 0.605, d_overlap: 0.983\n",
      "[Epoch 80/200] [Batch 160/938] [D loss: 0.329923] [G loss: 2.656603]\n",
      "g_overlap: 0.461, d_overlap: 0.979\n",
      "[Epoch 80/200] [Batch 560/938] [D loss: 0.363426] [G loss: 1.203293]\n",
      "g_overlap: 0.187, d_overlap: 0.980\n",
      "[Epoch 81/200] [Batch 22/938] [D loss: 0.297026] [G loss: 1.884565]\n",
      "g_overlap: 0.345, d_overlap: 0.983\n",
      "[Epoch 81/200] [Batch 422/938] [D loss: 0.322665] [G loss: 2.269567]\n",
      "g_overlap: 0.493, d_overlap: 0.988\n",
      "[Epoch 81/200] [Batch 822/938] [D loss: 0.352202] [G loss: 1.998136]\n",
      "g_overlap: 0.446, d_overlap: 0.974\n",
      "[Epoch 82/200] [Batch 284/938] [D loss: 0.385593] [G loss: 1.943907]\n",
      "g_overlap: 0.649, d_overlap: 0.984\n",
      "[Epoch 82/200] [Batch 684/938] [D loss: 0.353914] [G loss: 1.909528]\n",
      "g_overlap: 0.652, d_overlap: 0.982\n",
      "[Epoch 83/200] [Batch 146/938] [D loss: 0.309135] [G loss: 1.859707]\n",
      "g_overlap: 0.608, d_overlap: 0.981\n",
      "[Epoch 83/200] [Batch 546/938] [D loss: 0.328072] [G loss: 1.292889]\n",
      "g_overlap: 0.572, d_overlap: 0.984\n",
      "[Epoch 84/200] [Batch 8/938] [D loss: 0.336990] [G loss: 2.028699]\n",
      "g_overlap: 0.641, d_overlap: 0.978\n",
      "[Epoch 84/200] [Batch 408/938] [D loss: 0.412383] [G loss: 1.411447]\n",
      "g_overlap: 0.570, d_overlap: 0.976\n",
      "[Epoch 84/200] [Batch 808/938] [D loss: 0.331110] [G loss: 2.030114]\n",
      "g_overlap: 0.432, d_overlap: 0.969\n",
      "[Epoch 85/200] [Batch 270/938] [D loss: 0.319923] [G loss: 1.654907]\n",
      "g_overlap: 0.267, d_overlap: 0.977\n",
      "[Epoch 85/200] [Batch 670/938] [D loss: 0.336769] [G loss: 1.621487]\n",
      "g_overlap: 0.562, d_overlap: 0.981\n",
      "[Epoch 86/200] [Batch 132/938] [D loss: 0.380899] [G loss: 2.265900]\n",
      "g_overlap: 0.487, d_overlap: 0.983\n",
      "[Epoch 86/200] [Batch 532/938] [D loss: 0.322064] [G loss: 2.134083]\n",
      "g_overlap: 0.560, d_overlap: 0.969\n",
      "[Epoch 86/200] [Batch 932/938] [D loss: 0.365321] [G loss: 1.826561]\n",
      "g_overlap: 0.494, d_overlap: 0.950\n",
      "[Epoch 87/200] [Batch 394/938] [D loss: 0.535566] [G loss: 2.737545]\n",
      "g_overlap: 0.629, d_overlap: 0.983\n",
      "[Epoch 87/200] [Batch 794/938] [D loss: 0.292143] [G loss: 1.681697]\n",
      "g_overlap: 0.479, d_overlap: 0.977\n",
      "[Epoch 88/200] [Batch 256/938] [D loss: 0.435243] [G loss: 1.733339]\n",
      "g_overlap: 0.047, d_overlap: 0.956\n",
      "[Epoch 88/200] [Batch 656/938] [D loss: 0.336869] [G loss: 2.056362]\n",
      "g_overlap: 0.538, d_overlap: 0.980\n",
      "[Epoch 89/200] [Batch 118/938] [D loss: 0.428541] [G loss: 2.267854]\n",
      "g_overlap: 0.541, d_overlap: 0.954\n",
      "[Epoch 89/200] [Batch 518/938] [D loss: 0.420859] [G loss: 2.057123]\n",
      "g_overlap: 0.570, d_overlap: 0.971\n",
      "[Epoch 89/200] [Batch 918/938] [D loss: 0.408960] [G loss: 1.748549]\n",
      "g_overlap: 0.514, d_overlap: 0.977\n",
      "[Epoch 90/200] [Batch 380/938] [D loss: 0.378016] [G loss: 1.379416]\n",
      "g_overlap: 0.487, d_overlap: 0.967\n",
      "[Epoch 90/200] [Batch 780/938] [D loss: 0.454504] [G loss: 1.872608]\n",
      "g_overlap: 0.609, d_overlap: 0.981\n",
      "[Epoch 91/200] [Batch 242/938] [D loss: 0.350669] [G loss: 1.699678]\n",
      "g_overlap: 0.439, d_overlap: 0.980\n",
      "[Epoch 91/200] [Batch 642/938] [D loss: 0.445632] [G loss: 1.720228]\n",
      "g_overlap: 0.458, d_overlap: 0.978\n",
      "[Epoch 92/200] [Batch 104/938] [D loss: 0.367509] [G loss: 1.815187]\n",
      "g_overlap: 0.402, d_overlap: 0.969\n",
      "[Epoch 92/200] [Batch 504/938] [D loss: 0.375994] [G loss: 1.763150]\n",
      "g_overlap: 0.573, d_overlap: 0.979\n",
      "[Epoch 92/200] [Batch 904/938] [D loss: 0.357477] [G loss: 1.885782]\n",
      "g_overlap: 0.495, d_overlap: 0.972\n",
      "[Epoch 93/200] [Batch 366/938] [D loss: 0.372992] [G loss: 1.938428]\n",
      "g_overlap: 0.506, d_overlap: 0.972\n",
      "[Epoch 93/200] [Batch 766/938] [D loss: 0.312817] [G loss: 1.531914]\n",
      "g_overlap: 0.592, d_overlap: 0.977\n",
      "[Epoch 94/200] [Batch 228/938] [D loss: 0.406851] [G loss: 1.685677]\n",
      "g_overlap: 0.244, d_overlap: 0.966\n",
      "[Epoch 94/200] [Batch 628/938] [D loss: 0.350349] [G loss: 1.937462]\n",
      "g_overlap: 0.476, d_overlap: 0.960\n",
      "[Epoch 95/200] [Batch 90/938] [D loss: 0.347012] [G loss: 1.816447]\n",
      "g_overlap: 0.521, d_overlap: 0.978\n",
      "[Epoch 95/200] [Batch 490/938] [D loss: 0.438630] [G loss: 1.453928]\n",
      "g_overlap: 0.653, d_overlap: 0.979\n",
      "[Epoch 95/200] [Batch 890/938] [D loss: 0.466639] [G loss: 1.140516]\n",
      "g_overlap: 0.550, d_overlap: 0.984\n",
      "[Epoch 96/200] [Batch 352/938] [D loss: 0.309540] [G loss: 1.494148]\n",
      "g_overlap: 0.492, d_overlap: 0.972\n",
      "[Epoch 96/200] [Batch 752/938] [D loss: 0.287472] [G loss: 2.020736]\n",
      "g_overlap: 0.389, d_overlap: 0.964\n",
      "[Epoch 97/200] [Batch 214/938] [D loss: 0.369789] [G loss: 1.514830]\n",
      "g_overlap: 0.514, d_overlap: 0.971\n",
      "[Epoch 97/200] [Batch 614/938] [D loss: 0.444898] [G loss: 1.579564]\n",
      "g_overlap: 0.603, d_overlap: 0.970\n",
      "[Epoch 98/200] [Batch 76/938] [D loss: 0.360946] [G loss: 1.710027]\n",
      "g_overlap: 0.554, d_overlap: 0.977\n",
      "[Epoch 98/200] [Batch 476/938] [D loss: 0.345910] [G loss: 1.873766]\n",
      "g_overlap: 0.403, d_overlap: 0.970\n",
      "[Epoch 98/200] [Batch 876/938] [D loss: 0.360625] [G loss: 1.603112]\n",
      "g_overlap: 0.411, d_overlap: 0.964\n",
      "[Epoch 99/200] [Batch 338/938] [D loss: 0.253076] [G loss: 1.987868]\n",
      "g_overlap: 0.601, d_overlap: 0.976\n",
      "[Epoch 99/200] [Batch 738/938] [D loss: 0.301122] [G loss: 1.574197]\n",
      "g_overlap: 0.587, d_overlap: 0.968\n",
      "[Epoch 100/200] [Batch 200/938] [D loss: 0.377169] [G loss: 2.086661]\n",
      "g_overlap: 0.590, d_overlap: 0.965\n",
      "[Epoch 100/200] [Batch 600/938] [D loss: 0.417032] [G loss: 1.983061]\n",
      "g_overlap: 0.650, d_overlap: 0.975\n",
      "[Epoch 101/200] [Batch 62/938] [D loss: 0.379528] [G loss: 1.733731]\n",
      "g_overlap: 0.698, d_overlap: 0.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/200] [Batch 462/938] [D loss: 0.435212] [G loss: 1.536953]\n",
      "g_overlap: 0.414, d_overlap: 0.979\n",
      "[Epoch 101/200] [Batch 862/938] [D loss: 0.394028] [G loss: 2.133150]\n",
      "g_overlap: 0.774, d_overlap: 0.970\n",
      "[Epoch 102/200] [Batch 324/938] [D loss: 0.390229] [G loss: 1.539506]\n",
      "g_overlap: 0.615, d_overlap: 0.963\n",
      "[Epoch 102/200] [Batch 724/938] [D loss: 0.282862] [G loss: 1.773213]\n",
      "g_overlap: 0.074, d_overlap: 0.968\n",
      "[Epoch 103/200] [Batch 186/938] [D loss: 0.380751] [G loss: 1.690520]\n",
      "g_overlap: 0.325, d_overlap: 0.975\n",
      "[Epoch 103/200] [Batch 586/938] [D loss: 0.379199] [G loss: 1.789472]\n",
      "g_overlap: 0.565, d_overlap: 0.960\n",
      "[Epoch 104/200] [Batch 48/938] [D loss: 0.449372] [G loss: 1.857889]\n",
      "g_overlap: 0.593, d_overlap: 0.963\n",
      "[Epoch 104/200] [Batch 448/938] [D loss: 0.517307] [G loss: 1.942997]\n",
      "g_overlap: 0.671, d_overlap: 0.967\n",
      "[Epoch 104/200] [Batch 848/938] [D loss: 0.349956] [G loss: 1.494830]\n",
      "g_overlap: 0.516, d_overlap: 0.964\n",
      "[Epoch 105/200] [Batch 310/938] [D loss: 0.438908] [G loss: 1.528018]\n",
      "g_overlap: 0.252, d_overlap: 0.967\n",
      "[Epoch 105/200] [Batch 710/938] [D loss: 0.370046] [G loss: 1.684551]\n",
      "g_overlap: 0.467, d_overlap: 0.975\n",
      "[Epoch 106/200] [Batch 172/938] [D loss: 0.301077] [G loss: 1.600975]\n",
      "g_overlap: 0.659, d_overlap: 0.973\n",
      "[Epoch 106/200] [Batch 572/938] [D loss: 0.449410] [G loss: 2.062984]\n",
      "g_overlap: 0.659, d_overlap: 0.967\n",
      "[Epoch 107/200] [Batch 34/938] [D loss: 0.387442] [G loss: 1.916752]\n",
      "g_overlap: 0.665, d_overlap: 0.965\n",
      "[Epoch 107/200] [Batch 434/938] [D loss: 0.404440] [G loss: 1.794159]\n",
      "g_overlap: 0.592, d_overlap: 0.970\n",
      "[Epoch 107/200] [Batch 834/938] [D loss: 0.414813] [G loss: 1.920388]\n",
      "g_overlap: 0.471, d_overlap: 0.957\n",
      "[Epoch 108/200] [Batch 296/938] [D loss: 0.369867] [G loss: 2.084691]\n",
      "g_overlap: 0.399, d_overlap: 0.957\n",
      "[Epoch 108/200] [Batch 696/938] [D loss: 0.404165] [G loss: 1.537290]\n",
      "g_overlap: 0.150, d_overlap: 0.966\n",
      "[Epoch 109/200] [Batch 158/938] [D loss: 0.464784] [G loss: 2.088761]\n",
      "g_overlap: 0.727, d_overlap: 0.953\n",
      "[Epoch 109/200] [Batch 558/938] [D loss: 0.383236] [G loss: 1.781867]\n",
      "g_overlap: 0.519, d_overlap: 0.962\n",
      "[Epoch 110/200] [Batch 20/938] [D loss: 0.371829] [G loss: 1.697370]\n",
      "g_overlap: 0.533, d_overlap: 0.955\n",
      "[Epoch 110/200] [Batch 420/938] [D loss: 0.357276] [G loss: 2.419643]\n",
      "g_overlap: 0.522, d_overlap: 0.966\n",
      "[Epoch 110/200] [Batch 820/938] [D loss: 0.337233] [G loss: 1.602257]\n",
      "g_overlap: 0.661, d_overlap: 0.985\n",
      "[Epoch 111/200] [Batch 282/938] [D loss: 0.387360] [G loss: 1.457837]\n",
      "g_overlap: 0.598, d_overlap: 0.962\n",
      "[Epoch 111/200] [Batch 682/938] [D loss: 0.372641] [G loss: 1.912673]\n",
      "g_overlap: 0.392, d_overlap: 0.974\n",
      "[Epoch 112/200] [Batch 144/938] [D loss: 0.423102] [G loss: 1.252036]\n",
      "g_overlap: 0.590, d_overlap: 0.976\n",
      "[Epoch 112/200] [Batch 544/938] [D loss: 0.315998] [G loss: 1.523455]\n",
      "g_overlap: 0.109, d_overlap: 0.966\n",
      "[Epoch 113/200] [Batch 6/938] [D loss: 0.286210] [G loss: 2.245517]\n",
      "g_overlap: 0.326, d_overlap: 0.961\n",
      "[Epoch 113/200] [Batch 406/938] [D loss: 0.423636] [G loss: 1.725894]\n",
      "g_overlap: 0.579, d_overlap: 0.974\n",
      "[Epoch 113/200] [Batch 806/938] [D loss: 0.392774] [G loss: 2.285280]\n",
      "g_overlap: 0.643, d_overlap: 0.967\n",
      "[Epoch 114/200] [Batch 268/938] [D loss: 0.418543] [G loss: 1.674309]\n",
      "g_overlap: 0.458, d_overlap: 0.977\n",
      "[Epoch 114/200] [Batch 668/938] [D loss: 0.422345] [G loss: 1.257906]\n",
      "g_overlap: 0.544, d_overlap: 0.966\n",
      "[Epoch 115/200] [Batch 130/938] [D loss: 0.334293] [G loss: 1.712509]\n",
      "g_overlap: 0.621, d_overlap: 0.967\n",
      "[Epoch 115/200] [Batch 530/938] [D loss: 0.392596] [G loss: 1.901852]\n",
      "g_overlap: 0.495, d_overlap: 0.967\n",
      "[Epoch 115/200] [Batch 930/938] [D loss: 0.358857] [G loss: 1.986469]\n",
      "g_overlap: 0.559, d_overlap: 0.944\n",
      "[Epoch 116/200] [Batch 392/938] [D loss: 0.397382] [G loss: 1.633546]\n",
      "g_overlap: 0.430, d_overlap: 0.974\n",
      "[Epoch 116/200] [Batch 792/938] [D loss: 0.374605] [G loss: 2.022799]\n",
      "g_overlap: 0.494, d_overlap: 0.954\n",
      "[Epoch 117/200] [Batch 254/938] [D loss: 0.342709] [G loss: 1.718671]\n",
      "g_overlap: 0.471, d_overlap: 0.961\n",
      "[Epoch 117/200] [Batch 654/938] [D loss: 0.372493] [G loss: 1.611635]\n",
      "g_overlap: 0.551, d_overlap: 0.964\n",
      "[Epoch 118/200] [Batch 116/938] [D loss: 0.395061] [G loss: 1.910214]\n",
      "g_overlap: 0.553, d_overlap: 0.976\n",
      "[Epoch 118/200] [Batch 516/938] [D loss: 0.452152] [G loss: 1.892287]\n",
      "g_overlap: 0.501, d_overlap: 0.966\n",
      "[Epoch 118/200] [Batch 916/938] [D loss: 0.461387] [G loss: 1.694648]\n",
      "g_overlap: 0.621, d_overlap: 0.976\n",
      "[Epoch 119/200] [Batch 378/938] [D loss: 0.417423] [G loss: 2.268370]\n",
      "g_overlap: 0.409, d_overlap: 0.962\n",
      "[Epoch 119/200] [Batch 778/938] [D loss: 0.418304] [G loss: 1.891569]\n",
      "g_overlap: 0.715, d_overlap: 0.968\n",
      "[Epoch 120/200] [Batch 240/938] [D loss: 0.353196] [G loss: 1.748226]\n",
      "g_overlap: 0.650, d_overlap: 0.973\n",
      "[Epoch 120/200] [Batch 640/938] [D loss: 0.415123] [G loss: 1.484527]\n",
      "g_overlap: 0.647, d_overlap: 0.960\n",
      "[Epoch 121/200] [Batch 102/938] [D loss: 0.304063] [G loss: 1.606124]\n",
      "g_overlap: 0.374, d_overlap: 0.958\n",
      "[Epoch 121/200] [Batch 502/938] [D loss: 0.456314] [G loss: 1.765231]\n",
      "g_overlap: 0.585, d_overlap: 0.967\n",
      "[Epoch 121/200] [Batch 902/938] [D loss: 0.487276] [G loss: 1.479698]\n",
      "g_overlap: 0.534, d_overlap: 0.964\n",
      "[Epoch 122/200] [Batch 364/938] [D loss: 0.467847] [G loss: 2.405168]\n",
      "g_overlap: 0.496, d_overlap: 0.957\n",
      "[Epoch 122/200] [Batch 764/938] [D loss: 0.495462] [G loss: 1.168625]\n",
      "g_overlap: 0.503, d_overlap: 0.968\n",
      "[Epoch 123/200] [Batch 226/938] [D loss: 0.335506] [G loss: 1.384174]\n",
      "g_overlap: 0.480, d_overlap: 0.968\n",
      "[Epoch 123/200] [Batch 626/938] [D loss: 0.421083] [G loss: 1.962923]\n",
      "g_overlap: 0.259, d_overlap: 0.968\n",
      "[Epoch 124/200] [Batch 88/938] [D loss: 0.340722] [G loss: 2.134256]\n",
      "g_overlap: 0.544, d_overlap: 0.964\n",
      "[Epoch 124/200] [Batch 488/938] [D loss: 0.406688] [G loss: 1.484621]\n",
      "g_overlap: 0.634, d_overlap: 0.945\n",
      "[Epoch 124/200] [Batch 888/938] [D loss: 0.431490] [G loss: 1.797147]\n",
      "g_overlap: 0.575, d_overlap: 0.957\n",
      "[Epoch 125/200] [Batch 350/938] [D loss: 0.462297] [G loss: 1.712883]\n",
      "g_overlap: 0.618, d_overlap: 0.956\n",
      "[Epoch 125/200] [Batch 750/938] [D loss: 0.403938] [G loss: 1.617939]\n",
      "g_overlap: 0.663, d_overlap: 0.962\n",
      "[Epoch 126/200] [Batch 212/938] [D loss: 0.429754] [G loss: 1.344229]\n",
      "g_overlap: 0.441, d_overlap: 0.966\n",
      "[Epoch 126/200] [Batch 612/938] [D loss: 0.397245] [G loss: 1.873724]\n",
      "g_overlap: 0.727, d_overlap: 0.954\n",
      "[Epoch 127/200] [Batch 74/938] [D loss: 0.322195] [G loss: 1.714256]\n",
      "g_overlap: 0.519, d_overlap: 0.964\n",
      "[Epoch 127/200] [Batch 474/938] [D loss: 0.394774] [G loss: 1.807005]\n",
      "g_overlap: 0.609, d_overlap: 0.951\n",
      "[Epoch 127/200] [Batch 874/938] [D loss: 0.370763] [G loss: 1.280985]\n",
      "g_overlap: 0.582, d_overlap: 0.954\n",
      "[Epoch 128/200] [Batch 336/938] [D loss: 0.344432] [G loss: 1.859253]\n",
      "g_overlap: 0.542, d_overlap: 0.970\n",
      "[Epoch 128/200] [Batch 736/938] [D loss: 0.369181] [G loss: 1.894364]\n",
      "g_overlap: 0.550, d_overlap: 0.953\n",
      "[Epoch 129/200] [Batch 198/938] [D loss: 0.359888] [G loss: 1.532870]\n",
      "g_overlap: 0.479, d_overlap: 0.955\n",
      "[Epoch 129/200] [Batch 598/938] [D loss: 0.382822] [G loss: 1.785342]\n",
      "g_overlap: 0.787, d_overlap: 0.955\n",
      "[Epoch 130/200] [Batch 60/938] [D loss: 0.445883] [G loss: 1.893665]\n",
      "g_overlap: 0.613, d_overlap: 0.947\n",
      "[Epoch 130/200] [Batch 460/938] [D loss: 0.427154] [G loss: 1.603249]\n",
      "g_overlap: 0.599, d_overlap: 0.942\n",
      "[Epoch 130/200] [Batch 860/938] [D loss: 0.370136] [G loss: 1.755764]\n",
      "g_overlap: 0.553, d_overlap: 0.954\n",
      "[Epoch 131/200] [Batch 322/938] [D loss: 0.413730] [G loss: 1.190542]\n",
      "g_overlap: 0.484, d_overlap: 0.948\n",
      "[Epoch 131/200] [Batch 722/938] [D loss: 0.361182] [G loss: 1.652665]\n",
      "g_overlap: 0.471, d_overlap: 0.964\n",
      "[Epoch 132/200] [Batch 184/938] [D loss: 0.373415] [G loss: 1.724518]\n",
      "g_overlap: 0.678, d_overlap: 0.961\n",
      "[Epoch 132/200] [Batch 584/938] [D loss: 0.452870] [G loss: 1.473927]\n",
      "g_overlap: 0.615, d_overlap: 0.973\n",
      "[Epoch 133/200] [Batch 46/938] [D loss: 0.351636] [G loss: 1.619251]\n",
      "g_overlap: 0.655, d_overlap: 0.965\n",
      "[Epoch 133/200] [Batch 446/938] [D loss: 0.374446] [G loss: 1.856187]\n",
      "g_overlap: 0.445, d_overlap: 0.967\n",
      "[Epoch 133/200] [Batch 846/938] [D loss: 0.393594] [G loss: 1.709931]\n",
      "g_overlap: 0.652, d_overlap: 0.973\n",
      "[Epoch 134/200] [Batch 308/938] [D loss: 0.443585] [G loss: 1.300663]\n",
      "g_overlap: 0.556, d_overlap: 0.962\n",
      "[Epoch 134/200] [Batch 708/938] [D loss: 0.350140] [G loss: 1.632177]\n",
      "g_overlap: 0.517, d_overlap: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 135/200] [Batch 170/938] [D loss: 0.447023] [G loss: 1.267025]\n",
      "g_overlap: 0.586, d_overlap: 0.955\n",
      "[Epoch 135/200] [Batch 570/938] [D loss: 0.335465] [G loss: 1.860396]\n",
      "g_overlap: 0.588, d_overlap: 0.951\n",
      "[Epoch 136/200] [Batch 32/938] [D loss: 0.378256] [G loss: 1.913929]\n",
      "g_overlap: 0.596, d_overlap: 0.967\n",
      "[Epoch 136/200] [Batch 432/938] [D loss: 0.368296] [G loss: 1.717222]\n",
      "g_overlap: 0.657, d_overlap: 0.960\n",
      "[Epoch 136/200] [Batch 832/938] [D loss: 0.414494] [G loss: 1.936895]\n",
      "g_overlap: 0.620, d_overlap: 0.940\n",
      "[Epoch 137/200] [Batch 294/938] [D loss: 0.400214] [G loss: 1.786833]\n",
      "g_overlap: 0.715, d_overlap: 0.951\n",
      "[Epoch 137/200] [Batch 694/938] [D loss: 0.397614] [G loss: 1.622740]\n",
      "g_overlap: 0.580, d_overlap: 0.944\n",
      "[Epoch 138/200] [Batch 156/938] [D loss: 0.412416] [G loss: 1.596734]\n",
      "g_overlap: 0.617, d_overlap: 0.958\n",
      "[Epoch 138/200] [Batch 556/938] [D loss: 0.328048] [G loss: 1.584204]\n",
      "g_overlap: 0.387, d_overlap: 0.969\n",
      "[Epoch 139/200] [Batch 18/938] [D loss: 0.403134] [G loss: 1.459932]\n",
      "g_overlap: 0.535, d_overlap: 0.973\n",
      "[Epoch 139/200] [Batch 418/938] [D loss: 0.380140] [G loss: 1.938053]\n",
      "g_overlap: 0.529, d_overlap: 0.970\n",
      "[Epoch 139/200] [Batch 818/938] [D loss: 0.327719] [G loss: 1.656127]\n",
      "g_overlap: 0.463, d_overlap: 0.964\n",
      "[Epoch 140/200] [Batch 280/938] [D loss: 0.400368] [G loss: 1.505012]\n",
      "g_overlap: 0.451, d_overlap: 0.963\n",
      "[Epoch 140/200] [Batch 680/938] [D loss: 0.385023] [G loss: 1.472754]\n",
      "g_overlap: 0.595, d_overlap: 0.958\n",
      "[Epoch 141/200] [Batch 142/938] [D loss: 0.419271] [G loss: 1.511736]\n",
      "g_overlap: 0.707, d_overlap: 0.957\n",
      "[Epoch 141/200] [Batch 542/938] [D loss: 0.355658] [G loss: 1.414762]\n",
      "g_overlap: 0.679, d_overlap: 0.950\n",
      "[Epoch 142/200] [Batch 4/938] [D loss: 0.391819] [G loss: 1.794112]\n",
      "g_overlap: 0.381, d_overlap: 0.947\n",
      "[Epoch 142/200] [Batch 404/938] [D loss: 0.459117] [G loss: 1.667105]\n",
      "g_overlap: 0.525, d_overlap: 0.959\n",
      "[Epoch 142/200] [Batch 804/938] [D loss: 0.480815] [G loss: 1.003242]\n",
      "g_overlap: 0.584, d_overlap: 0.970\n",
      "[Epoch 143/200] [Batch 266/938] [D loss: 0.389822] [G loss: 1.673921]\n",
      "g_overlap: 0.519, d_overlap: 0.949\n",
      "[Epoch 143/200] [Batch 666/938] [D loss: 0.515044] [G loss: 1.325175]\n",
      "g_overlap: 0.533, d_overlap: 0.957\n",
      "[Epoch 144/200] [Batch 128/938] [D loss: 0.382284] [G loss: 1.882269]\n",
      "g_overlap: 0.706, d_overlap: 0.965\n",
      "[Epoch 144/200] [Batch 528/938] [D loss: 0.509698] [G loss: 1.252739]\n",
      "g_overlap: 0.726, d_overlap: 0.968\n",
      "[Epoch 144/200] [Batch 928/938] [D loss: 0.415141] [G loss: 1.268183]\n",
      "g_overlap: 0.486, d_overlap: 0.956\n",
      "[Epoch 145/200] [Batch 390/938] [D loss: 0.428455] [G loss: 1.566487]\n",
      "g_overlap: 0.654, d_overlap: 0.961\n",
      "[Epoch 145/200] [Batch 790/938] [D loss: 0.348061] [G loss: 1.505665]\n",
      "g_overlap: 0.692, d_overlap: 0.961\n",
      "[Epoch 146/200] [Batch 252/938] [D loss: 0.384748] [G loss: 1.551885]\n",
      "g_overlap: 0.589, d_overlap: 0.967\n",
      "[Epoch 146/200] [Batch 652/938] [D loss: 0.366437] [G loss: 1.299776]\n",
      "g_overlap: 0.674, d_overlap: 0.963\n",
      "[Epoch 147/200] [Batch 114/938] [D loss: 0.413122] [G loss: 1.489869]\n",
      "g_overlap: 0.554, d_overlap: 0.955\n",
      "[Epoch 147/200] [Batch 514/938] [D loss: 0.430892] [G loss: 1.583315]\n",
      "g_overlap: 0.502, d_overlap: 0.965\n",
      "[Epoch 147/200] [Batch 914/938] [D loss: 0.451466] [G loss: 1.472483]\n",
      "g_overlap: 0.557, d_overlap: 0.959\n",
      "[Epoch 148/200] [Batch 376/938] [D loss: 0.397205] [G loss: 1.286665]\n",
      "g_overlap: 0.641, d_overlap: 0.967\n",
      "[Epoch 148/200] [Batch 776/938] [D loss: 0.567414] [G loss: 1.420630]\n",
      "g_overlap: 0.571, d_overlap: 0.950\n",
      "[Epoch 149/200] [Batch 238/938] [D loss: 0.427619] [G loss: 1.377960]\n",
      "g_overlap: 0.594, d_overlap: 0.952\n",
      "[Epoch 149/200] [Batch 638/938] [D loss: 0.383622] [G loss: 1.509578]\n",
      "g_overlap: 0.606, d_overlap: 0.972\n",
      "[Epoch 150/200] [Batch 100/938] [D loss: 0.450895] [G loss: 1.015954]\n",
      "g_overlap: 0.499, d_overlap: 0.966\n",
      "[Epoch 150/200] [Batch 500/938] [D loss: 0.490053] [G loss: 1.202127]\n",
      "g_overlap: 0.622, d_overlap: 0.958\n",
      "[Epoch 150/200] [Batch 900/938] [D loss: 0.483277] [G loss: 1.468053]\n",
      "g_overlap: 0.635, d_overlap: 0.960\n",
      "[Epoch 151/200] [Batch 362/938] [D loss: 0.446750] [G loss: 1.832272]\n",
      "g_overlap: 0.568, d_overlap: 0.974\n",
      "[Epoch 151/200] [Batch 762/938] [D loss: 0.462449] [G loss: 1.679837]\n",
      "g_overlap: 0.658, d_overlap: 0.969\n",
      "[Epoch 152/200] [Batch 224/938] [D loss: 0.394481] [G loss: 1.702666]\n",
      "g_overlap: 0.594, d_overlap: 0.962\n",
      "[Epoch 152/200] [Batch 624/938] [D loss: 0.416145] [G loss: 1.398601]\n",
      "g_overlap: 0.363, d_overlap: 0.953\n",
      "[Epoch 153/200] [Batch 86/938] [D loss: 0.441959] [G loss: 1.990519]\n",
      "g_overlap: 0.591, d_overlap: 0.955\n",
      "[Epoch 153/200] [Batch 486/938] [D loss: 0.427915] [G loss: 1.434899]\n",
      "g_overlap: 0.653, d_overlap: 0.961\n",
      "[Epoch 153/200] [Batch 886/938] [D loss: 0.389100] [G loss: 1.784538]\n",
      "g_overlap: 0.689, d_overlap: 0.947\n",
      "[Epoch 154/200] [Batch 348/938] [D loss: 0.507603] [G loss: 1.313898]\n",
      "g_overlap: 0.468, d_overlap: 0.951\n",
      "[Epoch 154/200] [Batch 748/938] [D loss: 0.392137] [G loss: 1.664711]\n",
      "g_overlap: 0.512, d_overlap: 0.955\n",
      "[Epoch 155/200] [Batch 210/938] [D loss: 0.377604] [G loss: 1.810009]\n",
      "g_overlap: 0.722, d_overlap: 0.951\n",
      "[Epoch 155/200] [Batch 610/938] [D loss: 0.462322] [G loss: 1.470128]\n",
      "g_overlap: 0.591, d_overlap: 0.972\n",
      "[Epoch 156/200] [Batch 72/938] [D loss: 0.405525] [G loss: 1.783521]\n",
      "g_overlap: 0.583, d_overlap: 0.958\n",
      "[Epoch 156/200] [Batch 472/938] [D loss: 0.438153] [G loss: 1.590389]\n",
      "g_overlap: 0.580, d_overlap: 0.966\n",
      "[Epoch 156/200] [Batch 872/938] [D loss: 0.348850] [G loss: 1.734277]\n",
      "g_overlap: 0.514, d_overlap: 0.928\n",
      "[Epoch 157/200] [Batch 334/938] [D loss: 0.423538] [G loss: 1.457939]\n",
      "g_overlap: 0.566, d_overlap: 0.965\n",
      "[Epoch 157/200] [Batch 734/938] [D loss: 0.436095] [G loss: 1.511265]\n",
      "g_overlap: 0.639, d_overlap: 0.936\n",
      "[Epoch 158/200] [Batch 196/938] [D loss: 0.436268] [G loss: 1.805480]\n",
      "g_overlap: 0.636, d_overlap: 0.952\n",
      "[Epoch 158/200] [Batch 596/938] [D loss: 0.475009] [G loss: 1.258137]\n",
      "g_overlap: 0.601, d_overlap: 0.960\n",
      "[Epoch 159/200] [Batch 58/938] [D loss: 0.403080] [G loss: 1.631875]\n",
      "g_overlap: 0.602, d_overlap: 0.959\n",
      "[Epoch 159/200] [Batch 458/938] [D loss: 0.537566] [G loss: 1.459820]\n",
      "g_overlap: 0.637, d_overlap: 0.954\n",
      "[Epoch 159/200] [Batch 858/938] [D loss: 0.364267] [G loss: 1.496990]\n",
      "g_overlap: 0.602, d_overlap: 0.946\n",
      "[Epoch 160/200] [Batch 320/938] [D loss: 0.544952] [G loss: 1.596101]\n",
      "g_overlap: 0.593, d_overlap: 0.965\n",
      "[Epoch 160/200] [Batch 720/938] [D loss: 0.507139] [G loss: 1.061156]\n",
      "g_overlap: 0.149, d_overlap: 0.951\n",
      "[Epoch 161/200] [Batch 182/938] [D loss: 0.357879] [G loss: 1.730649]\n",
      "g_overlap: 0.303, d_overlap: 0.945\n",
      "[Epoch 161/200] [Batch 582/938] [D loss: 0.475374] [G loss: 1.301718]\n",
      "g_overlap: 0.668, d_overlap: 0.940\n",
      "[Epoch 162/200] [Batch 44/938] [D loss: 0.435545] [G loss: 1.659205]\n",
      "g_overlap: 0.557, d_overlap: 0.971\n",
      "[Epoch 162/200] [Batch 444/938] [D loss: 0.403999] [G loss: 1.868727]\n",
      "g_overlap: 0.394, d_overlap: 0.963\n",
      "[Epoch 162/200] [Batch 844/938] [D loss: 0.438418] [G loss: 1.401496]\n",
      "g_overlap: 0.545, d_overlap: 0.954\n",
      "[Epoch 163/200] [Batch 306/938] [D loss: 0.438983] [G loss: 1.449775]\n",
      "g_overlap: 0.692, d_overlap: 0.934\n",
      "[Epoch 163/200] [Batch 706/938] [D loss: 0.403291] [G loss: 1.165876]\n",
      "g_overlap: 0.486, d_overlap: 0.972\n",
      "[Epoch 164/200] [Batch 168/938] [D loss: 0.433189] [G loss: 1.226333]\n",
      "g_overlap: 0.679, d_overlap: 0.948\n",
      "[Epoch 164/200] [Batch 568/938] [D loss: 0.393435] [G loss: 1.783585]\n",
      "g_overlap: 0.551, d_overlap: 0.955\n",
      "[Epoch 165/200] [Batch 30/938] [D loss: 0.439462] [G loss: 1.493858]\n",
      "g_overlap: 0.400, d_overlap: 0.946\n",
      "[Epoch 165/200] [Batch 430/938] [D loss: 0.377265] [G loss: 1.366291]\n",
      "g_overlap: 0.697, d_overlap: 0.947\n",
      "[Epoch 165/200] [Batch 830/938] [D loss: 0.416558] [G loss: 1.433602]\n",
      "g_overlap: 0.647, d_overlap: 0.950\n",
      "[Epoch 166/200] [Batch 292/938] [D loss: 0.377061] [G loss: 1.611646]\n",
      "g_overlap: 0.703, d_overlap: 0.962\n",
      "[Epoch 166/200] [Batch 692/938] [D loss: 0.445217] [G loss: 1.990036]\n",
      "g_overlap: 0.407, d_overlap: 0.954\n",
      "[Epoch 167/200] [Batch 154/938] [D loss: 0.440757] [G loss: 1.106465]\n",
      "g_overlap: 0.288, d_overlap: 0.961\n",
      "[Epoch 167/200] [Batch 554/938] [D loss: 0.459926] [G loss: 1.517820]\n",
      "g_overlap: 0.782, d_overlap: 0.952\n",
      "[Epoch 168/200] [Batch 16/938] [D loss: 0.437445] [G loss: 1.688362]\n",
      "g_overlap: 0.648, d_overlap: 0.958\n",
      "[Epoch 168/200] [Batch 416/938] [D loss: 0.409548] [G loss: 1.636918]\n",
      "g_overlap: 0.639, d_overlap: 0.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 168/200] [Batch 816/938] [D loss: 0.458938] [G loss: 1.190712]\n",
      "g_overlap: 0.655, d_overlap: 0.964\n",
      "[Epoch 169/200] [Batch 278/938] [D loss: 0.403495] [G loss: 1.376967]\n",
      "g_overlap: 0.392, d_overlap: 0.969\n",
      "[Epoch 169/200] [Batch 678/938] [D loss: 0.417382] [G loss: 1.701041]\n",
      "g_overlap: 0.649, d_overlap: 0.950\n",
      "[Epoch 170/200] [Batch 140/938] [D loss: 0.448443] [G loss: 1.455063]\n",
      "g_overlap: 0.586, d_overlap: 0.963\n",
      "[Epoch 170/200] [Batch 540/938] [D loss: 0.360299] [G loss: 1.488030]\n",
      "g_overlap: 0.596, d_overlap: 0.958\n",
      "[Epoch 171/200] [Batch 2/938] [D loss: 0.504446] [G loss: 1.243537]\n",
      "g_overlap: 0.670, d_overlap: 0.952\n",
      "[Epoch 171/200] [Batch 402/938] [D loss: 0.441988] [G loss: 1.651920]\n",
      "g_overlap: 0.614, d_overlap: 0.944\n",
      "[Epoch 171/200] [Batch 802/938] [D loss: 0.444387] [G loss: 1.376938]\n",
      "g_overlap: 0.616, d_overlap: 0.952\n",
      "[Epoch 172/200] [Batch 264/938] [D loss: 0.406249] [G loss: 1.563797]\n",
      "g_overlap: 0.584, d_overlap: 0.964\n",
      "[Epoch 172/200] [Batch 664/938] [D loss: 0.424963] [G loss: 1.309105]\n",
      "g_overlap: 0.641, d_overlap: 0.966\n",
      "[Epoch 173/200] [Batch 126/938] [D loss: 0.475775] [G loss: 1.438864]\n",
      "g_overlap: 0.630, d_overlap: 0.964\n",
      "[Epoch 173/200] [Batch 526/938] [D loss: 0.466892] [G loss: 1.107918]\n",
      "g_overlap: 0.581, d_overlap: 0.968\n",
      "[Epoch 173/200] [Batch 926/938] [D loss: 0.460480] [G loss: 1.459139]\n",
      "g_overlap: 0.592, d_overlap: 0.964\n",
      "[Epoch 174/200] [Batch 388/938] [D loss: 0.432459] [G loss: 1.279159]\n",
      "g_overlap: 0.658, d_overlap: 0.956\n",
      "[Epoch 174/200] [Batch 788/938] [D loss: 0.448427] [G loss: 1.246060]\n",
      "g_overlap: 0.536, d_overlap: 0.957\n",
      "[Epoch 175/200] [Batch 250/938] [D loss: 0.387857] [G loss: 1.897384]\n",
      "g_overlap: 0.478, d_overlap: 0.971\n",
      "[Epoch 175/200] [Batch 650/938] [D loss: 0.420923] [G loss: 1.645107]\n",
      "g_overlap: 0.648, d_overlap: 0.952\n",
      "[Epoch 176/200] [Batch 112/938] [D loss: 0.473486] [G loss: 1.556863]\n",
      "g_overlap: 0.665, d_overlap: 0.961\n",
      "[Epoch 176/200] [Batch 512/938] [D loss: 0.497803] [G loss: 1.354131]\n",
      "g_overlap: 0.558, d_overlap: 0.954\n",
      "[Epoch 176/200] [Batch 912/938] [D loss: 0.499349] [G loss: 1.734736]\n",
      "g_overlap: 0.668, d_overlap: 0.944\n",
      "[Epoch 177/200] [Batch 374/938] [D loss: 0.464237] [G loss: 1.223709]\n",
      "g_overlap: 0.640, d_overlap: 0.968\n",
      "[Epoch 177/200] [Batch 774/938] [D loss: 0.394116] [G loss: 1.434247]\n",
      "g_overlap: 0.634, d_overlap: 0.964\n",
      "[Epoch 178/200] [Batch 236/938] [D loss: 0.434768] [G loss: 1.480755]\n",
      "g_overlap: 0.610, d_overlap: 0.936\n",
      "[Epoch 178/200] [Batch 636/938] [D loss: 0.420155] [G loss: 1.306349]\n",
      "g_overlap: 0.556, d_overlap: 0.927\n",
      "[Epoch 179/200] [Batch 98/938] [D loss: 0.456742] [G loss: 1.336056]\n",
      "g_overlap: 0.597, d_overlap: 0.958\n",
      "[Epoch 179/200] [Batch 498/938] [D loss: 0.478451] [G loss: 1.240662]\n",
      "g_overlap: 0.514, d_overlap: 0.958\n",
      "[Epoch 179/200] [Batch 898/938] [D loss: 0.410375] [G loss: 1.528728]\n",
      "g_overlap: 0.612, d_overlap: 0.949\n",
      "[Epoch 180/200] [Batch 360/938] [D loss: 0.447085] [G loss: 1.231756]\n",
      "g_overlap: 0.611, d_overlap: 0.959\n",
      "[Epoch 180/200] [Batch 760/938] [D loss: 0.376865] [G loss: 1.641861]\n",
      "g_overlap: 0.706, d_overlap: 0.944\n",
      "[Epoch 181/200] [Batch 222/938] [D loss: 0.386490] [G loss: 1.238027]\n",
      "g_overlap: 0.720, d_overlap: 0.957\n",
      "[Epoch 181/200] [Batch 622/938] [D loss: 0.474116] [G loss: 1.641295]\n",
      "g_overlap: 0.567, d_overlap: 0.972\n",
      "[Epoch 182/200] [Batch 84/938] [D loss: 0.435940] [G loss: 1.897113]\n",
      "g_overlap: 0.718, d_overlap: 0.974\n",
      "[Epoch 182/200] [Batch 484/938] [D loss: 0.425712] [G loss: 1.626846]\n",
      "g_overlap: 0.402, d_overlap: 0.936\n",
      "[Epoch 182/200] [Batch 884/938] [D loss: 0.481302] [G loss: 1.694777]\n",
      "g_overlap: 0.584, d_overlap: 0.958\n",
      "[Epoch 183/200] [Batch 346/938] [D loss: 0.431035] [G loss: 1.484606]\n",
      "g_overlap: 0.616, d_overlap: 0.981\n",
      "[Epoch 183/200] [Batch 746/938] [D loss: 0.533536] [G loss: 1.348113]\n",
      "g_overlap: 0.642, d_overlap: 0.958\n",
      "[Epoch 184/200] [Batch 208/938] [D loss: 0.382866] [G loss: 1.654098]\n",
      "g_overlap: 0.672, d_overlap: 0.952\n",
      "[Epoch 184/200] [Batch 608/938] [D loss: 0.473753] [G loss: 1.327273]\n",
      "g_overlap: 0.624, d_overlap: 0.960\n",
      "[Epoch 185/200] [Batch 70/938] [D loss: 0.444923] [G loss: 1.928726]\n",
      "g_overlap: 0.573, d_overlap: 0.960\n",
      "[Epoch 185/200] [Batch 470/938] [D loss: 0.414084] [G loss: 1.426036]\n",
      "g_overlap: 0.681, d_overlap: 0.934\n",
      "[Epoch 185/200] [Batch 870/938] [D loss: 0.437718] [G loss: 2.049660]\n",
      "g_overlap: 0.535, d_overlap: 0.968\n",
      "[Epoch 186/200] [Batch 332/938] [D loss: 0.391842] [G loss: 1.427159]\n",
      "g_overlap: 0.578, d_overlap: 0.954\n",
      "[Epoch 186/200] [Batch 732/938] [D loss: 0.421602] [G loss: 1.545286]\n",
      "g_overlap: 0.518, d_overlap: 0.964\n",
      "[Epoch 187/200] [Batch 194/938] [D loss: 0.399401] [G loss: 1.526976]\n",
      "g_overlap: 0.606, d_overlap: 0.943\n",
      "[Epoch 187/200] [Batch 594/938] [D loss: 0.469829] [G loss: 1.578755]\n",
      "g_overlap: 0.580, d_overlap: 0.950\n",
      "[Epoch 188/200] [Batch 56/938] [D loss: 0.434193] [G loss: 1.375856]\n",
      "g_overlap: 0.615, d_overlap: 0.967\n",
      "[Epoch 188/200] [Batch 456/938] [D loss: 0.417748] [G loss: 1.324886]\n",
      "g_overlap: 0.557, d_overlap: 0.956\n",
      "[Epoch 188/200] [Batch 856/938] [D loss: 0.492403] [G loss: 1.427984]\n",
      "g_overlap: 0.486, d_overlap: 0.967\n",
      "[Epoch 189/200] [Batch 318/938] [D loss: 0.474917] [G loss: 1.521717]\n",
      "g_overlap: 0.620, d_overlap: 0.954\n",
      "[Epoch 189/200] [Batch 718/938] [D loss: 0.434806] [G loss: 1.539220]\n",
      "g_overlap: 0.677, d_overlap: 0.957\n",
      "[Epoch 190/200] [Batch 180/938] [D loss: 0.409161] [G loss: 1.946096]\n",
      "g_overlap: 0.537, d_overlap: 0.962\n",
      "[Epoch 190/200] [Batch 580/938] [D loss: 0.437581] [G loss: 1.362417]\n",
      "g_overlap: 0.527, d_overlap: 0.970\n",
      "[Epoch 191/200] [Batch 42/938] [D loss: 0.391244] [G loss: 1.579935]\n",
      "g_overlap: 0.303, d_overlap: 0.946\n",
      "[Epoch 191/200] [Batch 442/938] [D loss: 0.463333] [G loss: 1.583179]\n",
      "g_overlap: 0.503, d_overlap: 0.954\n",
      "[Epoch 191/200] [Batch 842/938] [D loss: 0.384621] [G loss: 1.350694]\n",
      "g_overlap: 0.577, d_overlap: 0.949\n",
      "[Epoch 192/200] [Batch 304/938] [D loss: 0.441563] [G loss: 1.511063]\n",
      "g_overlap: 0.529, d_overlap: 0.957\n",
      "[Epoch 192/200] [Batch 704/938] [D loss: 0.441995] [G loss: 1.295909]\n",
      "g_overlap: 0.392, d_overlap: 0.956\n",
      "[Epoch 193/200] [Batch 166/938] [D loss: 0.468831] [G loss: 1.329561]\n",
      "g_overlap: 0.674, d_overlap: 0.930\n",
      "[Epoch 193/200] [Batch 566/938] [D loss: 0.427936] [G loss: 1.217842]\n",
      "g_overlap: 0.693, d_overlap: 0.951\n",
      "[Epoch 194/200] [Batch 28/938] [D loss: 0.445470] [G loss: 1.119686]\n",
      "g_overlap: 0.643, d_overlap: 0.957\n",
      "[Epoch 194/200] [Batch 428/938] [D loss: 0.435907] [G loss: 1.592854]\n",
      "g_overlap: 0.511, d_overlap: 0.948\n",
      "[Epoch 194/200] [Batch 828/938] [D loss: 0.386048] [G loss: 1.630486]\n",
      "g_overlap: 0.771, d_overlap: 0.959\n",
      "[Epoch 195/200] [Batch 290/938] [D loss: 0.405198] [G loss: 1.355880]\n",
      "g_overlap: 0.613, d_overlap: 0.948\n",
      "[Epoch 195/200] [Batch 690/938] [D loss: 0.483308] [G loss: 1.271306]\n",
      "g_overlap: 0.581, d_overlap: 0.946\n",
      "[Epoch 196/200] [Batch 152/938] [D loss: 0.538347] [G loss: 1.329445]\n",
      "g_overlap: 0.568, d_overlap: 0.951\n",
      "[Epoch 196/200] [Batch 552/938] [D loss: 0.412817] [G loss: 1.374168]\n",
      "g_overlap: 0.574, d_overlap: 0.949\n",
      "[Epoch 197/200] [Batch 14/938] [D loss: 0.400302] [G loss: 1.628954]\n",
      "g_overlap: 0.644, d_overlap: 0.958\n",
      "[Epoch 197/200] [Batch 414/938] [D loss: 0.421628] [G loss: 1.606640]\n",
      "g_overlap: 0.640, d_overlap: 0.963\n",
      "[Epoch 197/200] [Batch 814/938] [D loss: 0.402152] [G loss: 1.424382]\n",
      "g_overlap: 0.632, d_overlap: 0.955\n",
      "[Epoch 198/200] [Batch 276/938] [D loss: 0.511579] [G loss: 1.969334]\n",
      "g_overlap: 0.627, d_overlap: 0.937\n",
      "[Epoch 198/200] [Batch 676/938] [D loss: 0.380337] [G loss: 1.628492]\n",
      "g_overlap: 0.548, d_overlap: 0.956\n",
      "[Epoch 199/200] [Batch 138/938] [D loss: 0.411013] [G loss: 1.278080]\n",
      "g_overlap: 0.610, d_overlap: 0.966\n",
      "[Epoch 199/200] [Batch 538/938] [D loss: 0.436601] [G loss: 1.403672]\n",
      "g_overlap: 0.521, d_overlap: 0.969\n"
     ]
    }
   ],
   "source": [
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "g_overlap_list = []\n",
    "d_overlap_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        # -----------------\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        # ---------------------\n",
    "\n",
    "        # ---------------------\n",
    "        # Monitor Progress\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:# and batches_done != 0:\n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % \\\n",
    "                   (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()))\n",
    "            \n",
    "            batches_done_str = str(batches_done).zfill(8)\n",
    "            \n",
    "            ## save the losses\n",
    "            g_loss_list.append(g_loss.item())\n",
    "            d_loss_list.append(d_loss.item())\n",
    "            \n",
    "            #----------------------\n",
    "            # Generator Grad Overlap\n",
    "            gen_imgs = generator(z)\n",
    " \n",
    "            ## loss computed via built-in CE function\n",
    "            g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "            ## loss computed by scratch (needed to compute 2nd deriv)\n",
    "            g_loss_homebrew = - torch.log(discriminator(gen_imgs)).mean()\n",
    "            #print(\"g loss comparison: \", g_loss, g_loss_homebrew)\n",
    "            \n",
    "            ## this computes g_i, ||g||^2\n",
    "            g_loss_grad = torch.autograd.grad(g_loss_homebrew, generator.parameters(), create_graph=True)\n",
    "            g_loss_grad_norm_sq = 0\n",
    "            for g in g_loss_grad:\n",
    "                g_loss_grad_norm_sq = g_loss_grad_norm_sq + g.pow(2).sum()\n",
    "\n",
    "            ## this computes 2(g^T H)_i, 4 ||H g||^2\n",
    "            g_loss_grad2 = torch.autograd.grad(g_loss_grad_norm_sq, generator.parameters(), create_graph=True)\n",
    "            g_loss_grad2_norm_sq = 0\n",
    "            for g in g_loss_grad2:\n",
    "                g_loss_grad2_norm_sq = g_loss_grad2_norm_sq + g.pow(2).sum()\n",
    "\n",
    "            ## this computes 2(g^T H g)\n",
    "            g_overlap_raw = 0\n",
    "            for i in range(len(g_loss_grad2)):\n",
    "                g_overlap_raw = g_overlap_raw + torch.mul(g_loss_grad[i], g_loss_grad2[i]).sum() \n",
    "\n",
    "            ## finally, compute the overlap (g^T H g)/(||g|| ||H g||)\n",
    "            g_overlap = g_overlap_raw/torch.sqrt(g_loss_grad_norm_sq)/torch.sqrt(g_loss_grad2_norm_sq)\n",
    "            g_overlap_list.append(g_overlap.data.cpu().numpy())\n",
    "            #----------------------\n",
    "\n",
    "            #----------------------\n",
    "            # Discriminator Grad Overlap\n",
    "            gen_imgs = generator(z)\n",
    "\n",
    "            ## loss computed via built-in CE function\n",
    "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            ## loss computed by scratch (needed to compute 2nd deriv)\n",
    "            real_loss_homebrew = - torch.log(discriminator(real_imgs)).mean()\n",
    "            fake_loss_homebrew = - torch.log(1.0-discriminator(gen_imgs.detach())).mean()\n",
    "            d_loss_homebrew = (real_loss_homebrew + fake_loss_homebrew) / 2            \n",
    "            #print(\"d loss comparison: \", d_loss, d_loss_homebrew)\n",
    "\n",
    "            ## this computes g_i, ||g||^2\n",
    "            d_loss_grad = torch.autograd.grad(g_loss_homebrew, discriminator.parameters(), create_graph=True)\n",
    "            d_loss_grad_norm_sq = 0\n",
    "            for g in d_loss_grad:\n",
    "                d_loss_grad_norm_sq = d_loss_grad_norm_sq + g.pow(2).sum()\n",
    "\n",
    "            ## this computes 2(g^T H)_i, 4 ||H g||^2\n",
    "            d_loss_grad2 = torch.autograd.grad(d_loss_grad_norm_sq, discriminator.parameters(), create_graph=True)\n",
    "            d_loss_grad2_norm_sq = 0\n",
    "            for g in d_loss_grad2:\n",
    "                d_loss_grad2_norm_sq = d_loss_grad2_norm_sq + g.pow(2).sum()\n",
    "\n",
    "            ## this computes 2(g^T H g)\n",
    "            d_overlap_raw = 0\n",
    "            for i in range(len(d_loss_grad2)):\n",
    "                d_overlap_raw = d_overlap_raw + torch.mul(d_loss_grad[i], d_loss_grad2[i]).sum() \n",
    "\n",
    "            ## finally, compute the overlap (g^T H g)/(||g|| ||H g||)\n",
    "            d_overlap = d_overlap_raw/torch.sqrt(d_loss_grad_norm_sq)/torch.sqrt(d_loss_grad2_norm_sq)\n",
    "            d_overlap_list.append(d_overlap.data.cpu().numpy())\n",
    "            #----------------------\n",
    "\n",
    "            ## print the overlaps\n",
    "            print('g_overlap: %.3f, d_overlap: %.3f' % (g_overlap, d_overlap))\n",
    "\n",
    "#             # plot a grid of samples\n",
    "#             x = gen_imgs.data[:,0,:,:].cpu()\n",
    "#             plt.figure(figsize=(6, 6))\n",
    "#             plt.suptitle(\"Sampled Images, Batch_Num: \" + str(batches_done), fontsize=16)\n",
    "#             for j in range(64):\n",
    "#                 plt.subplot(8, 8, j + 1)\n",
    "#                 plt.imshow(x[j].reshape([28,28]), cmap='gray')\n",
    "#                 plt.xticks(())\n",
    "#                 plt.yticks(())\n",
    "#             plt.savefig('images/sample_images_' + batches_done_str + '.png')\n",
    "#             plt.close()\n",
    "#             #plt.show()\n",
    "\n",
    "#             Z = Variable(Tensor(np.random.normal(0, 1, (1000, latent_dim))))\n",
    "#             gen_imgs = generator(Z)\n",
    "#             X = gen_imgs.data[:,0,:,:].cpu().numpy()\n",
    "\n",
    "#             [K_distances_l2, K_angles_l2, K_distances_H, K_angles_H] = triangle_distributions(X, 10000)\n",
    "            \n",
    "#             ## plot the 2d triangle distance density plot (l2 norm)\n",
    "#             fig,ax = plt.subplots(1,1)\n",
    "#             ax1 = sns.kdeplot(K_distances_l2[:,0], K_distances_l2[:,1])\n",
    "#             ax1.set_xlim([0, 1.0])\n",
    "#             ax1.set_ylim([0, 1.0])\n",
    "#             ax1.set_xlabel(r\"$d_{mid}-d_{min}$\", fontsize=16)\n",
    "#             ax1.set_ylabel(r\"$d_{max}-d_{mid}$\", fontsize=16)\n",
    "#             ax1.set_title(\"Distance Density Plot (l2 distance), Batch_Num: \" + str(batches_done), fontsize=16)\n",
    "#             plt.savefig('images/distance_plot_l2_' + batches_done_str + '.png')\n",
    "#             plt.close()\n",
    "#             #plt.show()\n",
    "            \n",
    "#             ## plot the 2d triangle angle density plot (l2 norm)\n",
    "#             fig,ax = plt.subplots(1,1)\n",
    "#             ax2 = sns.kdeplot(K_angles_l2[:,0], K_angles_l2[:,1])\n",
    "#             ax2.set_xlim([0, 1.0])\n",
    "#             ax2.set_ylim([0, 1.0])\n",
    "#             ax2.set_xlabel(r\"$\\theta_{min}/\\theta_{mid}$\", fontsize=16)\n",
    "#             ax2.set_ylabel(r\"$\\theta_{min}/\\theta_{max}$\", fontsize=16)\n",
    "#             ax2.set_title(\"Angle Density Plot (l2 distance), Batch_Num: \" + str(batches_done), fontsize=16)\n",
    "#             plt.savefig('images/triangle_plot_l2_' + batches_done_str + '.png')\n",
    "#             plt.close()            \n",
    "#             #plt.show()\n",
    "    \n",
    "#             ## plot the 2d triangle distance density plot (H norm)\n",
    "#             fig,ax = plt.subplots(1,1)\n",
    "#             ax1 = sns.kdeplot(K_distances_H[:,0], K_distances_H[:,1])\n",
    "#             ax1.set_xlim([0, 1.0])\n",
    "#             ax1.set_ylim([0, 1.0])\n",
    "#             ax1.set_xlabel(r\"$d_{mid}-d_{min}$\", fontsize=16)\n",
    "#             ax1.set_ylabel(r\"$d_{max}-d_{mid}$\", fontsize=16)\n",
    "#             ax1.set_title(\"Distance Density Plot (H distance), Batch_Num: \" + str(batches_done), fontsize=16)\n",
    "#             plt.savefig('images/distance_plot_H_' + batches_done_str + '.png')\n",
    "#             plt.close()\n",
    "#             #plt.show()\n",
    "            \n",
    "#             ## plot the 2d triangle angle density plot (H norm)\n",
    "#             fig,ax = plt.subplots(1,1)\n",
    "#             ax2 = sns.kdeplot(K_angles_H[:,0], K_angles_H[:,1])\n",
    "#             ax2.set_xlim([0, 1.0])\n",
    "#             ax2.set_ylim([0, 1.0])\n",
    "#             ax2.set_xlabel(r\"$\\theta_{min}/\\theta_{mid}$\", fontsize=16)\n",
    "#             ax2.set_ylabel(r\"$\\theta_{min}/\\theta_{max}$\", fontsize=16)\n",
    "#             ax2.set_title(\"Angle Density Plot (H distance), Batch_Num: \" + str(batches_done), fontsize=16)\n",
    "#             plt.savefig('images/triangle_plot_H_' + batches_done_str + '.png')\n",
    "#             plt.close()            \n",
    "#             #plt.show()\n",
    "        #torch.cuda.empty_cache()\n",
    "        # ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_overlap_list, label='discriminator')\n",
    "plt.plot(g_overlap_list, label='generator')\n",
    "plt.title('Overlap(g, Hg)')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
